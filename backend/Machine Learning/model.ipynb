{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IcgXzvS3pCS",
        "outputId": "f2306727-9fea-4d9e-934b-7a6a630f68e5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "\n",
        "# 初始化資料集列表\n",
        "all_features_list = []\n",
        "all_labels_list = []\n",
        "\n",
        "batch_size = 1000\n",
        "counter = 0\n",
        "\n",
        "# 遍歷所有 CSV 檔案\n",
        "for i in range(500101001, 500119092):\n",
        "    file_path = f'rentbike/{i}.csv'\n",
        "    if not os.path.exists(file_path):\n",
        "        continue\n",
        "\n",
        "    # 讀取數據\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # 選取初始特徵\n",
        "    df = df[['sno', 'total', 'latitude', 'longitude', 'act', 'srcUpdateTime', 'available_rent_bikes']]\n",
        "\n",
        "    # 轉換 infoTime 為 datetime\n",
        "    df['srcUpdateTime'] = pd.to_datetime(df['srcUpdateTime'])\n",
        "\n",
        "    # 提取時間特徵\n",
        "    df['hour'] = df['srcUpdateTime'].dt.hour\n",
        "    df['minute'] = df['srcUpdateTime'].dt.minute\n",
        "    df['second'] = df['srcUpdateTime'].dt.second\n",
        "    df['weekday'] = df['srcUpdateTime'].dt.weekday  # 週幾\n",
        "\n",
        "    # 擴展後的特徵集\n",
        "    features = df[['sno', 'total', 'latitude', 'longitude', 'act', 'hour', 'minute', 'second', 'weekday']]\n",
        "    labels = df['available_rent_bikes']  # 預測 available_rent_bikes\n",
        "\n",
        "    all_features_list.append(features)\n",
        "    all_labels_list.append(labels)\n",
        "    counter += 1\n",
        "\n",
        "    # 每 batch_size 次進行一次合併，減少內存壓力\n",
        "    if counter % batch_size == 0:\n",
        "        all_features = pd.concat(all_features_list, ignore_index=True)\n",
        "        all_labels = pd.concat(all_labels_list, ignore_index=True)\n",
        "        all_features_list = []\n",
        "        all_labels_list = []\n",
        "        print(f\"Processed {counter} files.\")\n",
        "\n",
        "# 最後一批資料進行合併\n",
        "if counter % batch_size != 0:\n",
        "    all_features = pd.concat(all_features_list, ignore_index=True)\n",
        "    all_labels = pd.concat(all_labels_list, ignore_index=True)\n",
        "\n",
        "# 分割資料集\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_features, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# GBM 模型的網格搜索參數\n",
        "gbm_param_grid = {\n",
        "    'n_estimators': [500, 1000, 2000, 3000, 5000],\n",
        "    'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
        "    'max_depth': [5, 10, 15, 20, 25]\n",
        "}\n",
        "\n",
        "# 交叉驗證和網格搜索 GBM 模型\n",
        "gbm = GradientBoostingRegressor(random_state=42)\n",
        "gbm_grid_search = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "gbm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 最佳參數和評估 GBM 模型\n",
        "best_gbm = gbm_grid_search.best_estimator_\n",
        "y_pred_gbm = best_gbm.predict(X_test)\n",
        "mse_gbm = mean_squared_error(y_test, y_pred_gbm)\n",
        "rmse_gbm = mean_squared_error(y_test, y_pred_gbm, squared=False)\n",
        "mae_gbm = mean_absolute_error(y_test, y_pred_gbm)\n",
        "r2_gbm = r2_score(y_test, y_pred_gbm)\n",
        "print(f\"GBM Mean Squared Error: {mse_gbm}\")\n",
        "print(f\"GBM Root Mean Squared Error: {rmse_gbm}\")\n",
        "print(f\"GBM Mean Absolute Error: {mae_gbm}\")\n",
        "print(f\"GBM R^2 Score: {r2_gbm}\")\n",
        "print(f\"GBM Best Parameters: {gbm_grid_search.best_params_}\")\n",
        "joblib.dump(best_gbm, 'rent_bike_gbm_model.pkl')\n",
        "\n",
        "\n",
        "xgb_param_grid = {\n",
        "              'max_depth': [5, 10, 15, 20, 25],\n",
        "              'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
        "              'n_estimators': [500, 1000, 2000, 3000, 5000],\n",
        "              'min_child_weight': [0, 2, 5, 10, 20],\n",
        "              'max_delta_step': [0, 0.2, 0.6, 1, 2],\n",
        "              'subsample': [0.6, 0.7, 0.8, 0.85, 0.95],\n",
        "              'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "              'reg_alpha': [0, 0.25, 0.5, 0.75, 1],\n",
        "              'reg_lambda': [0.2, 0.4, 0.6, 0.8, 1],\n",
        "              'scale_pos_weight': [0.2, 0.4, 0.6, 0.8, 1]\n",
        "\n",
        "}\n",
        "\n",
        "# 交叉驗證和網格搜索 XGBoost 模型\n",
        "xgb_model = xgb.XGBRegressor(random_state=42)\n",
        "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "xgb_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 最佳參數和評估 XGBoost 模型\n",
        "best_xgb = xgb_grid_search.best_estimator_\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"XGBoost Root Mean Squared Error: {rmse_xgb}\")\n",
        "print(f\"XGBoost Mean Absolute Error: {mae_xgb}\")\n",
        "print(f\"XGBoost R^2 Score: {r2_xgb}\")\n",
        "print(f\"XGBoost Best Parameters: {xgb_grid_search.best_params_}\")\n",
        "joblib.dump(best_xgb, 'rent_bike_xgb_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGx20Vws4V4h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "\n",
        "# 初始化資料集列表\n",
        "all_features_list = []\n",
        "all_labels_list = []\n",
        "\n",
        "batch_size = 1000\n",
        "counter = 0\n",
        "\n",
        "# 遍歷所有 CSV 檔案\n",
        "for i in range(500101001, 500119092):\n",
        "    file_path = f'returnbike/{i}.csv'\n",
        "    if not os.path.exists(file_path):\n",
        "        continue\n",
        "    \n",
        "    # 讀取數據\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # 選取初始特徵\n",
        "    df = df[['sno', 'total', 'latitude', 'longitude', 'act', 'srcUpdateTime', 'available_return_bikes']]\n",
        "\n",
        "    # 轉換 infoTime 為 datetime\n",
        "    df['srcUpdateTime'] = pd.to_datetime(df['srcUpdateTime'])\n",
        "\n",
        "    # 提取時間特徵\n",
        "    df['hour'] = df['srcUpdateTime'].dt.hour\n",
        "    df['minute'] = df['srcUpdateTime'].dt.minute\n",
        "    df['second'] = df['srcUpdateTime'].dt.second\n",
        "    df['weekday'] = df['srcUpdateTime'].dt.weekday  # 週幾\n",
        "\n",
        "    # 擴展後的特徵集\n",
        "    features = df[['sno', 'total', 'latitude', 'longitude', 'act', 'hour', 'minute', 'second', 'weekday']]\n",
        "    labels = df['available_return_bikes']  # 預測 available_rent_bikes\n",
        "\n",
        "    all_features_list.append(features)\n",
        "    all_labels_list.append(labels)\n",
        "    counter += 1\n",
        "    \n",
        "    # 每 batch_size 次進行一次合併，減少內存壓力\n",
        "    if counter % batch_size == 0:\n",
        "        all_features = pd.concat(all_features_list, ignore_index=True)\n",
        "        all_labels = pd.concat(all_labels_list, ignore_index=True)\n",
        "        all_features_list = []\n",
        "        all_labels_list = []\n",
        "        print(f\"Processed {counter} files.\")\n",
        "\n",
        "# 最後一批資料進行合併\n",
        "if counter % batch_size != 0:\n",
        "    all_features = pd.concat(all_features_list, ignore_index=True)\n",
        "    all_labels = pd.concat(all_labels_list, ignore_index=True)\n",
        "\n",
        "# 分割資料集\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_features, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# GBM 模型的網格搜索參數\n",
        "gbm_param_grid = {\n",
        "    'n_estimators': [500, 1000, 2000, 3000, 5000],\n",
        "    'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
        "    'max_depth': [5, 10, 15, 20, 25]\n",
        "}\n",
        "\n",
        "# 交叉驗證和網格搜索 GBM 模型\n",
        "gbm = GradientBoostingRegressor(random_state=42)\n",
        "gbm_grid_search = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "gbm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 最佳參數和評估 GBM 模型\n",
        "best_gbm = gbm_grid_search.best_estimator_\n",
        "y_pred_gbm = best_gbm.predict(X_test)\n",
        "mse_gbm = mean_squared_error(y_test, y_pred_gbm)\n",
        "rmse_gbm = mean_squared_error(y_test, y_pred_gbm, squared=False)\n",
        "mae_gbm = mean_absolute_error(y_test, y_pred_gbm)\n",
        "r2_gbm = r2_score(y_test, y_pred_gbm)\n",
        "print(f\"GBM Mean Squared Error: {mse_gbm}\")\n",
        "print(f\"GBM Root Mean Squared Error: {rmse_gbm}\")\n",
        "print(f\"GBM Mean Absolute Error: {mae_gbm}\")\n",
        "print(f\"GBM R^2 Score: {r2_gbm}\")\n",
        "print(f\"GBM Best Parameters: {gbm_grid_search.best_params_}\")\n",
        "joblib.dump(best_gbm, 'return_bike_gbm_model.pkl')\n",
        "\n",
        "\n",
        "xgb_param_grid = {\n",
        "              'max_depth': [5, 10, 15, 20, 25],\n",
        "              'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
        "              'n_estimators': [500, 1000, 2000, 3000, 5000],\n",
        "              'min_child_weight': [0, 2, 5, 10, 20],\n",
        "              'max_delta_step': [0, 0.2, 0.6, 1, 2],\n",
        "              'subsample': [0.6, 0.7, 0.8, 0.85, 0.95],\n",
        "              'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "              'reg_alpha': [0, 0.25, 0.5, 0.75, 1],\n",
        "              'reg_lambda': [0.2, 0.4, 0.6, 0.8, 1],\n",
        "              'scale_pos_weight': [0.2, 0.4, 0.6, 0.8, 1]\n",
        "\n",
        "}\n",
        "\n",
        "# 交叉驗證和網格搜索 XGBoost 模型\n",
        "xgb_model = xgb.XGBRegressor(random_state=42)\n",
        "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "xgb_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 最佳參數和評估 XGBoost 模型\n",
        "best_xgb = xgb_grid_search.best_estimator_\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"XGBoost Root Mean Squared Error: {rmse_xgb}\")\n",
        "print(f\"XGBoost Mean Absolute Error: {mae_xgb}\")\n",
        "print(f\"XGBoost R^2 Score: {r2_xgb}\")\n",
        "print(f\"XGBoost Best Parameters: {xgb_grid_search.best_params_}\")\n",
        "joblib.dump(best_xgb, 'return_bike_xgb_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
